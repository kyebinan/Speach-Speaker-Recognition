{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from Lab3 import lab3_proto as proto3\n",
    "from Lab3 import lab3_tools as tools3\n",
    "from Lab2 import lab2_proto as proto2\n",
    "from Lab2 import lab2_tools as tools2\n",
    "from Lab1 import lab1_proto as proto1\n",
    "from Lab1 import lab1_tools as tools1\n",
    "from Lab2.prondict import prondict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Data for DNN Training \n",
    "\n",
    "## 4.1 Target Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ah_0', 'ah_1', 'ah_2', 'ao_0', 'ao_1', 'ao_2', 'ay_0', 'ay_1', 'ay_2', 'eh_0', 'eh_1', 'eh_2', 'ey_0', 'ey_1', 'ey_2', 'f_0', 'f_1', 'f_2', 'ih_0', 'ih_1', 'ih_2', 'iy_0', 'iy_1', 'iy_2', 'k_0', 'k_1', 'k_2', 'n_0', 'n_1', 'n_2', 'ow_0', 'ow_1', 'ow_2', 'r_0', 'r_1', 'r_2', 's_0', 's_1', 's_2', 'sil_0', 'sil_1', 'sil_2', 'sp_0', 't_0', 't_1', 't_2', 'th_0', 'th_1', 'th_2', 'uw_0', 'uw_1', 'uw_2', 'v_0', 'v_1', 'v_2', 'w_0', 'w_1', 'w_2', 'z_0', 'z_1', 'z_2']\n",
      "\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "phoneHMMs = np.load(\"./Lab2/lab2_models_all.npz\", allow_pickle=True)[\"phoneHMMs\"].item()\n",
    "phones = sorted(phoneHMMs.keys())\n",
    "nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
    "stateList = [ph + '_' + str(id) for ph in phones for id in range(nstates[ph])]\n",
    "print(stateList)\n",
    "print()\n",
    "print(stateList.index('ay_2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Forced Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordTrans: ['z', '4', '3']\n",
      "phoneTrans: ['sil', 'z', 'iy', 'r', 'ow', 'sp', 'f', 'ao', 'r', 'sp', 'th', 'r', 'iy', 'sp', 'sil']\n",
      "stateTrans[10]: r_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7231/2984385968.py:17: RuntimeWarning: divide by zero encountered in log\n",
      "  viterbiLoglik, viterbiPath = proto2.viterbi(obsloglik, np.log(utteranceHMM['startprob'][:-1]), np.log(utteranceHMM['transmat'][:-1, :-1]), forceFinalState=True)\n"
     ]
    }
   ],
   "source": [
    "# the dataset is not on the github due to the copyright\n",
    "filename = './../tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
    "samples, samplingrate = tools3.loadAudio(filename)\n",
    "lmfcc = proto1.mfcc(samples)\n",
    "\n",
    "wordTrans = list(tools3.path2info(filename)[2])  # Transcription using words\n",
    "print(f\"wordTrans: {wordTrans}\")\n",
    "\n",
    "phoneTrans = proto3.words2phones(wordTrans, prondict) # Transcription using phonemes\n",
    "print(f\"phoneTrans: {phoneTrans}\")\n",
    "\n",
    "utteranceHMM = proto2.concatHMMs(phoneHMMs, phoneTrans)\n",
    "stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans for stateid in range(nstates[phone])]  # Transcription using states\n",
    "print(f\"stateTrans[10]: {stateTrans[10]}\")\n",
    "\n",
    "obsloglik = tools2.log_multivariate_normal_density_diag(lmfcc, utteranceHMM[\"means\"], utteranceHMM[\"covars\"])\n",
    "viterbiLoglik, viterbiPath = proto2.viterbi(obsloglik, np.log(utteranceHMM['startprob'][:-1]), np.log(utteranceHMM['transmat'][:-1, :-1]), forceFinalState=True)\n",
    "\n",
    "viterbiStateTrans = [stateTrans[state] for state in viterbiPath]\n",
    "\n",
    "trans = tools3.frames2trans(viterbiStateTrans, outfilename='z43a.lab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mspec_res = proto1.mspec(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmfcc: True\n",
      "Our wordTrans: \n",
      "['z', '4', '3']\n",
      "Correct wordTrans: \n",
      "['z', '4', '3']\n",
      "Our phoneTrans: \n",
      "['sil', 'z', 'iy', 'r', 'ow', 'sp', 'f', 'ao', 'r', 'sp', 'th', 'r', 'iy', 'sp', 'sil']\n",
      "Correct phoneTrans: \n",
      "['sil', 'z', 'iy', 'r', 'ow', 'sp', 'f', 'ao', 'r', 'sp', 'th', 'r', 'iy', 'sp', 'sil']\n",
      "Our stateTrans: \n",
      "['sil_0', 'sil_1', 'sil_2', 'z_0', 'z_1', 'z_2', 'iy_0', 'iy_1', 'iy_2', 'r_0', 'r_1', 'r_2', 'ow_0', 'ow_1', 'ow_2', 'sp_0', 'f_0', 'f_1', 'f_2', 'ao_0', 'ao_1', 'ao_2', 'r_0', 'r_1', 'r_2', 'sp_0', 'th_0', 'th_1', 'th_2', 'r_0', 'r_1', 'r_2', 'iy_0', 'iy_1', 'iy_2', 'sp_0', 'sil_0', 'sil_1', 'sil_2']\n",
      "Correct stateTrans: \n",
      "['sil_0', 'sil_1', 'sil_2', 'z_0', 'z_1', 'z_2', 'iy_0', 'iy_1', 'iy_2', 'r_0', 'r_1', 'r_2', 'ow_0', 'ow_1', 'ow_2', 'sp_0', 'f_0', 'f_1', 'f_2', 'ao_0', 'ao_1', 'ao_2', 'r_0', 'r_1', 'r_2', 'sp_0', 'th_0', 'th_1', 'th_2', 'r_0', 'r_1', 'r_2', 'iy_0', 'iy_1', 'iy_2', 'sp_0', 'sil_0', 'sil_1', 'sil_2']\n",
      "obsloglik: True\n",
      "viterbiLoglik: True\n",
      "viterbiPath: True\n",
      "Our viterbiStateTrans: \n",
      "['sil_0', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_2', 'z_0', 'z_0', 'z_0', 'z_0', 'z_1', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_1', 'iy_2', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_1', 'r_2', 'ow_0', 'ow_1', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'f_0', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_2', 'ao_0', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'r_0', 'r_0', 'r_0', 'r_1', 'r_2', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_1', 'th_1', 'th_1', 'th_2', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_1', 'r_2', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_1', 'iy_1', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_1', 'sil_2']\n",
      "Correct viterbiStateTrans: \n",
      "['sil_0', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_2', 'z_0', 'z_0', 'z_0', 'z_0', 'z_1', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_1', 'iy_2', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_1', 'r_2', 'ow_0', 'ow_1', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'f_0', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_2', 'ao_0', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'r_0', 'r_0', 'r_0', 'r_1', 'r_2', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_1', 'th_1', 'th_1', 'th_2', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_1', 'r_2', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_1', 'iy_1', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_1', 'sil_2']\n"
     ]
    }
   ],
   "source": [
    "example = np.load(\"./Lab3/lab3_example.npz\", allow_pickle=True)[\"example\"].item()\n",
    "# Compare each variable with its corresponding value in the example dictionary\n",
    "\n",
    "print(f\"lmfcc: {np.allclose(lmfcc, example['lmfcc'])}\")\n",
    "print(f\"Our wordTrans: \\n{wordTrans}\\nCorrect wordTrans: \\n{example['wordTrans']}\")\n",
    "print(f\"Our phoneTrans: \\n{phoneTrans}\\nCorrect phoneTrans: \\n{example['phoneTrans']}\")\n",
    "print(f\"Our stateTrans: \\n{stateTrans}\\nCorrect stateTrans: \\n{example['stateTrans']}\")\n",
    "print(f\"obsloglik: {np.allclose(obsloglik, example['obsloglik'])}\")\n",
    "print(f\"viterbiLoglik: {np.allclose(viterbiLoglik, example['viterbiLoglik'])}\")\n",
    "print(f\"viterbiPath: {np.allclose(viterbiPath, example['viterbiPath'])}\")\n",
    "print(f\"Our viterbiStateTrans: \\n{viterbiStateTrans}\\nCorrect viterbiStateTrans: \\n{example['viterbiStateTrans']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(path):\n",
    "  data = []\n",
    "\n",
    "  for root, dirs, files in os.walk(path):\n",
    "    for file in tqdm(files):\n",
    "      if file.endswith('.wav'):\n",
    "        filename = os.path.join(root, file)\n",
    "        samples, samplingrate = tools3.loadAudio(filename)\n",
    "\n",
    "        lmfcc = proto1.mfcc(samples) # Features used for HMM & DNN\n",
    "        mspec_res = proto1.mspec(samples) # Features used for DNN\n",
    "\n",
    "        wordTrans = list(tools3.path2info(filename))[2]  # Transcription using words\n",
    "        phoneTrans = proto3.words2phones(wordTrans, prondict) # Transcription using phonemes\n",
    "        targets = proto3.forcedAlignment(lmfcc, phoneHMMs, phoneTrans) # Align states to each utterance\n",
    "\n",
    "        # converting targets to indices to save memory\n",
    "        target_idx = np.array([stateList.index(target) for target in targets])\n",
    "\n",
    "        data.append({'filename': filename, 'lmfcc': lmfcc,'mspec': mspec_res, 'targets': target_idx})\n",
    "\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction features from train data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/77 [00:00<?, ?it/s]/home/yohan/Documents/Cantique_des_Cantiques/Project/Speach/Speach-Speaker-Recognition/Lab3/lab3_proto.py:49: RuntimeWarning: divide by zero encountered in log\n",
      "  _, viterbi_path = viterbi(obslogik, np.log(utteranceHMM[\"startprob\"][:-1]), np.log(utteranceHMM[\"transmat\"][:-1, :-1]), forceFinalState=True)\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.61it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.00it/s]\n",
      "100%|██████████| 77/77 [00:11<00:00,  6.84it/s]\n",
      "100%|██████████| 77/77 [00:10<00:00,  7.44it/s]\n",
      "100%|██████████| 77/77 [00:11<00:00,  6.82it/s]\n",
      "100%|██████████| 77/77 [00:12<00:00,  6.23it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.08it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.16it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.95it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.98it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.50it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.09it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.50it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.20it/s]\n",
      "100%|██████████| 77/77 [00:09<00:00,  8.40it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.54it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.31it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.92it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.97it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.79it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.59it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.97it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.01it/s]\n",
      "100%|██████████| 77/77 [00:09<00:00,  8.54it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.00it/s]\n",
      "100%|██████████| 76/76 [00:06<00:00, 10.94it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.65it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.21it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.75it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.70it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.71it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.17it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.45it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.07it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.34it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.72it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.61it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.17it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.91it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.65it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.66it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.43it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.88it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.49it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.43it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.81it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.19it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.66it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.49it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.07it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.95it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.51it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.39it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.63it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.78it/s]\n",
      "100%|██████████| 77/77 [00:09<00:00,  8.38it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.70it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.95it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.19it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.88it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.31it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.76it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.71it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.63it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.94it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.18it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.95it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.87it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.24it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.09it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.80it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.86it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.93it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.04it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.00it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.05it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.73it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.23it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.28it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.37it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.13it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.82it/s]\n",
      "100%|██████████| 77/77 [00:09<00:00,  8.44it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.63it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.52it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.41it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.02it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.84it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.89it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.76it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.66it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.45it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.13it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.11it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.12it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 12.37it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.64it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.62it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.04it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.32it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.79it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.78it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.01it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.64it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.42it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.09it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.94it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.32it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.35it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.49it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.76it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.99it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.46it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.29it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.67it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.13it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.74it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.40it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.59it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.68it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.46it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.15it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.61it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.66it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.01it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.68it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.84it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.76it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.38it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.21it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.45it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.10it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.61it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.24it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.89it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.38it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.27it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.62it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.49it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.25it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.65it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.63it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.79it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.87it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.37it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.29it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.55it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.48it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.24it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.91it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.48it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.67it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.64it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.87it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.11it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.64it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.13it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.05it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.53it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.77it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.05it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.86it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.14it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.00it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.95it/s]\n",
      "100%|██████████| 77/77 [00:09<00:00,  8.54it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.20it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.27it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.19it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.88it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.26it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.92it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.17it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.25it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.69it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.52it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.73it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.77it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.97it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.63it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.03it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.08it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.73it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.59it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.67it/s]\n",
      "100%|██████████| 77/77 [00:09<00:00,  8.20it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.64it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.77it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.23it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.77it/s]\n",
      "100%|██████████| 77/77 [00:09<00:00,  8.47it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 12.11it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.66it/s]\n",
      "100%|██████████| 76/76 [00:06<00:00, 11.28it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.54it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.63it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.31it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.55it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.19it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.61it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.23it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.83it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.74it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.03it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.41it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.35it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.72it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.79it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.84it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.52it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.84it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.25it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.60it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.52it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.69it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.53it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.97it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.17it/s]\n",
      "100%|██████████| 77/77 [00:06<00:00, 11.19it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  8.97it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.44it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.86it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00, 10.59it/s]\n",
      "100%|██████████| 77/77 [00:07<00:00,  9.72it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Extraction features from train data\")\n",
    "trainData = feature_extraction('../tidigits/disc_4.1.1/tidigits/train')\n",
    "# Save the data to avoid computing it again\n",
    "np.savez('trainData.npz', trainData=trainData)\n",
    "\n",
    "print(\"Extracting features from test data\")\n",
    "testData = feature_extraction('../tidigits/disc_4.2.1/tidigits/test')\n",
    "np.savez('testData.npz', testData=testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataByGender(data_dict,gender, train_utterances):\n",
    "  train_data, val_data = [], []\n",
    "  for current_speaker in data_dict[gender].keys():\n",
    "    # if train_data contains 90 or more procent of total gender utterances, remaining data is stored as validation\n",
    "    if len(train_data) >= train_utterances:\n",
    "      #print(f\"len(train_data): {len(train_data)} > {train_utterances} --> Creating val set instead\")\n",
    "      val_data.extend(data_dict[gender][str(current_speaker)])\n",
    "    # Otherwise, we keep adding to train data until we achieve 90%\n",
    "    else:\n",
    "      #print(f\"len(train_data): {len(train_data)} < {train_utterances}\")\n",
    "      train_data.extend(data_dict[gender][str(current_speaker)])\n",
    "  print(f\"train_data: {len(train_data)} \\t val_data: {len(val_data)}\")\n",
    "  return train_data, val_data\n",
    "\n",
    "def splitData(total_data, split=0.1):\n",
    "  data_by_gender = {\"man\":{}, \"woman\": {}}\n",
    "  print(f\"Total_data length = {len(total_data)}\")\n",
    "  for data in total_data:\n",
    "    gender, speakerID, _, _ = tools3.path2info(data[\"filename\"])  # path2info returns tuple (gender, speakerID, digits, repetition)\n",
    "    if speakerID not in data_by_gender[gender]:\n",
    "      data_by_gender[gender][speakerID] = []\n",
    "    data_by_gender[gender][speakerID].append(data)\n",
    "\n",
    "  # Calculate total utterances by summing the lengths of each gender's list\n",
    "  total_male_utterances = sum(len(utterances) for utterances in data_by_gender[\"man\"].values())\n",
    "  total_female_utterances = sum(len(utterances) for utterances in data_by_gender[\"woman\"].values())\n",
    "\n",
    "  train_male_utterances = int(total_male_utterances * (1-split))     # compute how many male utterances to achieve 90%\n",
    "  train_female_utterances = int(total_female_utterances * (1-split)) # compute how many female utterances to achieve 90%\n",
    "  print(f\"total male utterances: {total_male_utterances}\\ntrain_male_utterances: {train_male_utterances}\")\n",
    "  print(f\"total female utterances: {total_female_utterances}\\ntrain_female_utterances: {train_female_utterances}\")\n",
    "\n",
    "  male_train_data, male_val_data = splitDataByGender(data_by_gender, \"man\", train_male_utterances)\n",
    "  female_train_data, female_val_data = splitDataByGender(data_by_gender, \"woman\", train_female_utterances)\n",
    "\n",
    "  train_data, val_data = [], []\n",
    "  train_data.extend(male_train_data)\n",
    "  train_data.extend(female_train_data)\n",
    "  val_data.extend(male_val_data)\n",
    "  val_data.extend(female_val_data)\n",
    "\n",
    "  print(f\"train data has {len(train_data)} elements\")\n",
    "  print(f\"val data has {len(val_data)} elements\")\n",
    "\n",
    "  return train_data, val_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainData has 8623 elements\n",
      "key: filename - ../tidigits/disc_4.1.1/tidigits/train/woman/cl/za.wav\n",
      "key: lmfcc - [[ 103.1708824   -82.31110635   14.29338738 ...  -38.65502294\n",
      "  -155.95559352  -48.36368006]\n",
      " [ 109.42118969  -11.18161627  117.72133428 ...    8.63922846\n",
      "   -40.50538129   21.4327149 ]\n",
      " [ 116.09423861  -46.88554472   25.04088065 ...  -75.15169037\n",
      "   -16.42606443   67.31586026]\n",
      " ...\n",
      " [ 203.16342222  109.37593821   16.40208643 ...  -27.98419695\n",
      "    -7.0104208     4.57830005]\n",
      " [ 164.15952204   87.7355812    85.18308825 ...  117.86320303\n",
      "    15.88054796   27.40947736]\n",
      " [ 170.64996493  107.48479268  124.78120348 ...   -5.24549154\n",
      "    49.41318624   10.30882344]]\n",
      "key: mspec - [[-0.12084544  1.03020631  0.46282056 ...  2.09551978  2.27765554\n",
      "   2.41654246]\n",
      " [ 2.54187435  3.06084006  3.07138977 ...  2.16677831  1.97251175\n",
      "   2.2343435 ]\n",
      " [ 1.52510378  2.79239405  1.89996556 ...  1.91766317  1.89914442\n",
      "   2.66109756]\n",
      " ...\n",
      " [ 4.40261508  3.47242441  2.87425463 ...  1.88805656  1.82493374\n",
      "   1.75817315]\n",
      " [ 5.22065891  3.47026996  1.56461146 ...  1.61069173  1.81613402\n",
      "   1.75268973]\n",
      " [ 4.78665577  4.24782695  3.10876783 ...  2.07996067  2.32817091\n",
      "   2.87288276]]\n",
      "key: targets - [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39 39 40 40 40 40 40 40 40 40 41 41 41 41 41 58 58 58 58\n",
      " 58 58 58 59 59 59 59 60 60 21 21 21 21 21 21 21 21 21 22 23 33 34 34 34\n",
      " 34 34 34 34 34 34 34 34 34 34 34 34 34 34 35 30 30 30 30 30 30 30 30 31\n",
      " 31 31 31 32 32 32 32 32 32 32 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39 39 39 39 39 40 41]\n"
     ]
    }
   ],
   "source": [
    "train_data_path = \"./trainData.npz\"\n",
    "test_data_path = \"./testData.npz\"\n",
    "trainData = np.load(train_data_path, allow_pickle=True)[\"trainData\"]\n",
    "testData = np.load(test_data_path, allow_pickle=True)[\"testData\"]\n",
    "\n",
    "print(f\"trainData has {len(trainData)} elements\")\n",
    "for key in trainData[0].keys():\n",
    "  print(f\"key: {key} - {trainData[0][key]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Acoustic Context (Dynamic Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_context(features, context=3):\n",
    "    \"\"\"\n",
    "    Augments the features by adding context frames around each time step in the feature matrix.\n",
    "\n",
    "    Args:\n",
    "    features (np.array): The original feature matrix where each row is a time step and columns are features.\n",
    "    context (int): The number of frames to include from before and after the current frame.\n",
    "\n",
    "    Returns:\n",
    "    np.array: An augmented feature matrix including context.\n",
    "    \"\"\"\n",
    "    rows, cols = features.shape\n",
    "    context_features = np.zeros((rows, cols * (2 * context + 1)))\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(-context, context + 1):\n",
    "            if 0 <= i + j < rows:\n",
    "                context_features[i, (j + context) * cols: (j + context + 1) * cols] = features[i + j]\n",
    "            else:\n",
    "                # Use mirroring for edge cases\n",
    "                mirrored_index = min(max(0, i + j), rows - 1)\n",
    "                context_features[i, (j + context) * cols: (j + context + 1) * cols] = features[mirrored_index]\n",
    "\n",
    "    return context_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103.1708824 , -82.31110635,  14.29338738, ...,   5.21621609,\n",
       "        -62.65111028, -48.97697333],\n",
       "       [103.1708824 , -82.31110635,  14.29338738, ..., -95.22756163,\n",
       "         16.2071291 ,  40.90530715],\n",
       "       [103.1708824 , -82.31110635,  14.29338738, ..., -72.15412933,\n",
       "        -66.9767564 , -71.81263328],\n",
       "       ...,\n",
       "       [153.06616189,  26.72406375,  29.80793612, ...,  -5.24549154,\n",
       "         49.41318624,  10.30882344],\n",
       "       [128.26044834,  37.93693872,  99.15316669, ...,  -5.24549154,\n",
       "         49.41318624,  10.30882344],\n",
       "       [177.653294  ,  91.29562855,  43.55066378, ...,  -5.24549154,\n",
       "         49.41318624,  10.30882344]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_context(trainData[0][\"lmfcc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Feature Standardisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocessing(totalData, _num_classes):\n",
    "  Ns = [len(data['targets']) for data in totalData]\n",
    "  N = sum(Ns)\n",
    "  D_lmfcc = trainData[0][\"lmfcc\"].shape[1]\n",
    "  D_mspec = trainData[0][\"mspec\"].shape[1]\n",
    "  X_lmfcc = np.zeros((N,D_lmfcc)).astype(\"float32\")\n",
    "  X_mspec = np.zeros((N,D_mspec)).astype(\"float32\")\n",
    "  Y = np.zeros(N)\n",
    "  print(f\"X_lmfcc: {X_lmfcc.shape}\")\n",
    "  print(f\"X_mspec: {X_mspec.shape}\")\n",
    "  print(f\"Y: {Y.shape}\")\n",
    "\n",
    "  startPointer = 0\n",
    "  for i, data in enumerate(totalData):\n",
    "    # add if statement for if we want to use context dependant data or not. Currently only uses non-context data as 4.5 is not done\n",
    "    X_lmfcc[startPointer: startPointer+Ns[i]] = data[\"lmfcc\"]\n",
    "    X_mspec[startPointer: startPointer+Ns[i]] = data[\"mspec\"]\n",
    "    Y[startPointer: startPointer+Ns[i]] = data[\"targets\"]\n",
    "    startPointer += Ns[i] # move pointer to next empty index\n",
    "\n",
    "  # class labels are 39., 40. and such and we need ints for the one_hot function\n",
    "  Y = F.one_hot(torch.tensor(Y, dtype=torch.int64), num_classes=_num_classes)\n",
    "  return X_lmfcc, X_mspec, Y\n",
    "\n",
    "# Creating scalers to standardize the data\n",
    "scalerLMFCC = StandardScaler()\n",
    "scalerMSPEC = StandardScaler()\n",
    "\n",
    "# Preprocessing the data\n",
    "trainLMFCCX, trainMSPECX, trainY = preprocessing(trainData, len(stateList))\n",
    "valLMFCCX, valMSPECX, valY = preprocessing(valData, len(stateList))\n",
    "testLMFCCX, testMSPECX, testY = preprocessing(testData, len(stateList))\n",
    "\n",
    "# Standardizing the data\n",
    "scalerLMFCC.fit(trainLMFCCX)\n",
    "trainLMFCCX = scalerLMFCC.transform(trainLMFCCX)\n",
    "valLMFCCX = scalerLMFCC.transform(valLMFCCX)\n",
    "testLMFCCX = scalerLMFCC.transform(testLMFCCX)\n",
    "\n",
    "scalerMSPEC.fit(trainMSPECX)\n",
    "trainMSPECX = scalerMSPEC.transform(trainMSPECX)\n",
    "valMSPECX = scalerMSPEC.transform(valMSPECX)\n",
    "testMSPECX = scalerMSPEC.transform(testMSPECX)\n",
    "\n",
    "print(f\"Preproccsed all data\")\n",
    "print(f\"trainLMFCCX: {trainLMFCCX.shape} \\t trainMSPECX: {trainMSPECX.shape} \\t trainY: {trainY.shape}\")\n",
    "print(f\"valLMFCCX: {valLMFCCX.shape} \\t valMSPECX: {valMSPECX.shape} \\t valY: {valY.shape}\")\n",
    "print(f\"testLMFCCX: {testLMFCCX.shape} \\t testMSPECX: {testMSPECX.shape} \\t testY: {testY.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Phoneme Recognition with Deep Neural Networks\n",
    "\n",
    "## 5.1 Detailed Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Possible Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
